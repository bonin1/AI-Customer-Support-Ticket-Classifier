# Advanced AI Customer Support Ticket Classifier

An enterprise-grade, intelligent system that automatically classifies customer support tickets with advanced ML operations, explainability, and compliance features. This production-ready solution goes far beyond basic classification to provide comprehensive MLOps capabilities and intelligent response generation.

## ğŸ¯ Core Features

- **Automated Classification**: Multi-model ensemble classification with confidence scoring
- **AI Response Generation**: Intelligent response generation using open-source LLMs from Hugging Face
- **Real-time Streaming**: Process tickets in real-time with WebSocket and Kafka support
- **Multi-modal Processing**: Handle text, images, audio, and documents in a single workflow
- **Advanced Models**: LSTM, BERT, ensemble methods with hyperparameter optimization
- **Interactive Dashboard**: Comprehensive Streamlit UI with 11 specialized tabs
- **Real-time Analytics**: Live performance monitoring and drift detection
- **Human-in-the-Loop**: Active learning with intelligent feedback collection
- **Enterprise Features**: Audit trails, GDPR compliance, and model versioning

## ğŸš€ Advanced Enterprise Features

### ğŸ¤– **AI Response Generator**
- Open-source LLM integration (GPT-2, FLAN-T5, DialoGPT, BlenderBot)
- Multiple generation methods (Template, AI, Hybrid)
- Multi-language and tone support (professional, friendly, empathetic)
- Response quality scoring and confidence assessment
- Batch response generation capabilities
- Customizable response templates with Jinja2 templating

### ğŸ“¡ **Real-time Streaming Processing**
- WebSocket server for real-time ticket ingestion
- Kafka integration for enterprise streaming workflows
- Configurable batch processing with adaptive timeouts
- Live performance monitoring and throughput tracking
- Automatic drift detection on streaming data
- Scalable architecture supporting high-volume ticket streams

### ğŸ­ **Multi-modal Classification**
- Text analysis with advanced NLP preprocessing
- Image processing with OCR text extraction (Tesseract, EasyOCR)
- Computer vision analysis using CLIP and BLIP models
- Audio processing with transcription capabilities
- Document parsing (PDF, DOCX, TXT files)
- Unified confidence scoring across all modalities

### ğŸ•µï¸ **Data Drift Detection**
- Real-time monitoring of input data distribution changes
- Statistical drift detection (KS test, PSI, Jensen-Shannon divergence)
- Automated alerts and recommendations
- Historical drift tracking and visualization

### ğŸ”„ **Online Learning System**
- Continuous model improvement with user feedback
- Incremental learning and model updates
- Confidence-based active learning
- Real-time performance tracking

### ğŸ”§ **Model Versioning & A/B Testing**
- Automated model versioning with metadata
- Statistical A/B testing framework
- Model deployment and rollback capabilities
- Performance comparison across versions

### ğŸ—ï¸ **Advanced Feature Engineering**
- Sophisticated NLP feature extraction
- Linguistic features (POS tags, named entities)
- Topic modeling and semantic analysis
- Domain-specific pattern recognition

### ğŸ“‹ **Audit & Compliance**
- Complete audit trails for all operations
- GDPR compliance (right to access, deletion, portability)
- Bias monitoring and fairness checks
- Automated data retention policies

### ğŸ¯ **Explainable AI**
- LIME and SHAP explanations
- Feature importance analysis
- Counterfactual explanations
- Bias detection and reporting

## ğŸ”§ Technologies Used

- **Advanced NLP**: spaCy, NLTK, transformers, LIME, SHAP
- **Machine Learning**: TensorFlow/Keras, scikit-learn, Optuna
- **LLM Integration**: Hugging Face Transformers, PyTorch, Jinja2
- **Computer Vision**: OpenCV, PIL, CLIP, BLIP, Tesseract, EasyOCR
- **Streaming**: WebSockets, Kafka, asyncio, aiohttp
- **Multi-modal**: LibROSA (audio), PyMuPDF (documents), python-docx
- **MLOps**: Model versioning, drift detection, online learning
- **Data Science**: Pandas, NumPy, SciPy for statistical analysis
- **Visualization**: Plotly, Matplotlib, Seaborn
- **UI**: Streamlit with 11 specialized dashboards
- **Compliance**: SQLite for audit logs, GDPR tools

## ğŸ“ Project Structure

```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Raw ticket data
â”‚   â”œâ”€â”€ processed/              # Cleaned and preprocessed data
â”‚   â””â”€â”€ sample/                 # Sample datasets for testing
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ saved_models/           # Trained model files and preprocessors
â”‚   â”œâ”€â”€ versions/               # Versioned models for A/B testing
â”‚   â”œâ”€â”€ tuning_results/         # Hyperparameter optimization results
â”‚   â””â”€â”€ monitoring.db           # Performance monitoring database
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_preprocessing.py   # Text cleaning and preprocessing
â”‚   â”œâ”€â”€ model_builder.py        # Model architecture definitions
â”‚   â”œâ”€â”€ train.py               # Training pipeline
â”‚   â”œâ”€â”€ predict.py             # Prediction utilities
â”‚   â”œâ”€â”€ ensemble_predictor.py  # Ensemble methods and voting
â”‚   â”œâ”€â”€ active_learning.py     # Active learning and sample selection
â”‚   â”œâ”€â”€ model_explainer.py     # LIME, SHAP, and explainability
â”‚   â”œâ”€â”€ hyperparameter_tuning.py # Automated hyperparameter optimization
â”‚   â”œâ”€â”€ performance_monitor.py # Real-time performance monitoring
â”‚   â”œâ”€â”€ drift_detector.py      # Data drift detection system
â”‚   â”œâ”€â”€ model_versioning.py    # Model versioning and A/B testing
â”‚   â”œâ”€â”€ feature_engineering.py # Advanced feature extraction
â”‚   â”œâ”€â”€ online_learner.py      # Online learning and feedback
â”‚   â”œâ”€â”€ response_generator.py  # AI Response Generation with LLMs
â”‚   â”œâ”€â”€ streaming_processor.py # Real-time streaming processing
â”‚   â”œâ”€â”€ multimodal_classifier.py # Multi-modal classification system
â”‚   â””â”€â”€ audit_system.py        # Audit trails and compliance
â”œâ”€â”€ streamlit_app/
â”‚   â”œâ”€â”€ app.py                 # Main Streamlit application (9 tabs)
â”‚   â”œâ”€â”€ components/            # UI components
â”‚   â””â”€â”€ utils/                 # Helper functions and utilities
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ exploratory_analysis.ipynb  # Data analysis and experiments
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ validate_data.py           # Data validation and quality checks
â”œâ”€â”€ test_advanced_features.py      # Test script for all components
â”œâ”€â”€ ADVANCED_FEATURES.md           # Detailed feature documentation
â””â”€â”€ requirements.txt               # All dependencies including advanced libs
```

## ğŸ–¥ï¸ Streamlit Dashboard Tabs

The web interface includes 11 specialized tabs:

1. **ğŸ” Single Prediction** - Individual ticket classification with confidence scoring
2. **ğŸ“‹ Batch Processing** - Bulk ticket processing and analysis
3. **ğŸ“Š Analytics Dashboard** - Comprehensive ticket data visualization and raw data exploration
4. **ğŸ”§ Model Management** - Model comparison and deployment
5. **ğŸ•µï¸ Data Drift Monitor** - Real-time drift detection and alerts
6. **ğŸ”„ Online Learning** - Feedback collection and continuous learning
7. **ğŸ—ï¸ Feature Engineering** - Advanced NLP feature extraction and analysis
8. **ğŸ“‹ Audit & Compliance** - Compliance monitoring and GDPR tools
9. **ğŸ¤– AI Response Generator** - Intelligent response generation using open-source LLMs
10. **ğŸ“¡ Real-time Streaming** - Live ticket processing with WebSocket and Kafka support
11. **ğŸ­ Multi-modal Processing** - Text, image, audio, and document classification

## ğŸš€ Quick Start

1. **Install Dependencies**
   ```bash
   pip install -r requirements.txt
   python -m spacy download en_core_web_sm
   ```

2. **Download NLTK Data (if using advanced features)**
   ```python
   import nltk
   nltk.download('punkt')
   nltk.download('stopwords')
   nltk.download('averaged_perceptron_tagger')
   nltk.download('maxent_ne_chunker')
   nltk.download('words')
   nltk.download('vader_lexicon')
   ```

3. **Prepare Data**
   - Place your ticket data in CSV format in `data/raw/`
   - Required columns: `ticket_id`, `customer_message`, `category`
   - Optional: `timestamp`, `priority`, `channel`

4. **Train Model with Advanced Features**
   ```bash
   # Basic training
   python src/train.py --data_path data/raw/tickets.csv --model_type lstm
   
   # With hyperparameter tuning
   python src/train.py --data_path data/raw/tickets.csv --model_type lstm --tune_hyperparameters
   
   # With advanced feature engineering
   python src/train.py --data_path data/raw/tickets.csv --model_type lstm --advanced_features
   ```

5. **Test Advanced Features**
   ```bash
   python test_advanced_features.py
   ```

6. **Run Enterprise Dashboard**
   ```bash
   streamlit run streamlit_app/app.py
   ```

## ğŸ¤– AI Response Generator Usage

The AI Response Generator uses open-source LLMs from Hugging Face to generate intelligent responses to customer support tickets.

### Supported Models
- **microsoft/DialoGPT-small/medium** - Conversational AI optimized for dialogue
- **google/flan-t5-small/base** - Instruction-following language model
- **facebook/blenderbot-400M-distill** - Open-domain chatbot
- **gpt2/gpt2-medium** - General-purpose language generation

### Generation Methods
- **Template**: Uses predefined templates with smart variable substitution
- **AI**: Pure LLM generation based on ticket content and context
- **Hybrid**: Combines templates with AI enhancement for optimal results

## ğŸ“Š Enhanced Analytics Dashboard

The Analytics Dashboard provides comprehensive visualization and exploration of all ticket data:

### Data Sources
- **Automatic Detection**: Loads data from sample, training, and test datasets
- **Session Integration**: Includes processed data from batch operations
- **File Location Tracking**: Shows exactly where each ticket is stored

### Comprehensive Analytics
- **Overall Statistics**: Total tickets, categories, priority distribution, channels
- **Visual Analytics**: Interactive charts for category, priority, channel, and time analysis
- **Raw Data Exploration**: Filterable and searchable ticket data with full-text display
- **Data Quality Metrics**: Missing values, duplicates, and data completeness
- **Export Capabilities**: Download filtered data as CSV for further analysis

### Interactive Features
- **Multi-level Filtering**: Filter by category, data source, priority, and channel
- **Detailed Ticket View**: Full ticket content with all metadata
- **Time Series Analysis**: Ticket volume trends and hourly patterns
- **Heatmap Visualizations**: Category vs priority distribution analysis

## ğŸ›ï¸ Configuration

### Environment Variables
```bash
ENABLE_GDPR=true
AUDIT_RETENTION_DAYS=365
DRIFT_THRESHOLD=0.05
LEARNING_RATE=0.01
```

### Advanced Features Configuration
```python
# Enable/disable advanced features in config.py
ENABLE_DRIFT_DETECTION = True
ENABLE_ONLINE_LEARNING = True
ENABLE_AUDIT_LOGGING = True
ENABLE_BIAS_MONITORING = True
```

## ğŸ“Š Supported Categories

- Billing & Payment
- Technical Issue
- Feature Request
- Account Management
- Product Information
- Refund & Return
- General Inquiry

## ğŸ”„ Workflow

1. **Data Collection**: Load ticket data from CSV/JSON
2. **Preprocessing**: Clean text, tokenize, vectorize
3. **Model Training**: Train classification models
4. **Evaluation**: Assess model performance
5. **Deployment**: Use Streamlit interface for predictions
6. **Feedback Loop**: Collect corrections and retrain

## ğŸ“ˆ Model Performance & Capabilities

The system supports multiple advanced model architectures:

### Model Types
- **LSTM**: Fast training, good baseline performance with attention mechanisms
- **BERT**: State-of-the-art transformer accuracy for text classification
- **Ensemble Methods**: Combines multiple models with intelligent voting
- **Online Learning**: Continuous adaptation with user feedback

### Performance Features
- **Real-time Monitoring**: Live accuracy and confidence tracking
- **Drift Detection**: Automatic detection of data distribution changes
- **A/B Testing**: Statistical comparison of model versions
- **Hyperparameter Optimization**: Automated tuning with Bayesian optimization

### Explainability
- **LIME Explanations**: Local interpretable model-agnostic explanations
- **SHAP Values**: Shapley additive explanations for feature importance
- **Attention Visualization**: For transformer models
- **Bias Detection**: Automated fairness monitoring

## ï¿½ Advanced Workflow

1. **Data Ingestion**: Load and validate ticket data
2. **Advanced Preprocessing**: Multi-stage text cleaning and feature engineering
3. **Model Training**: With hyperparameter optimization and ensemble methods
4. **Deployment**: Automated versioning and A/B testing setup
5. **Monitoring**: Real-time performance and drift detection
6. **Feedback Loop**: Online learning with human-in-the-loop corrections
7. **Compliance**: Audit logging and GDPR compliance checks
8. **Maintenance**: Automated model updates and data retention

## ğŸ“š Documentation

- **[ADVANCED_FEATURES.md](ADVANCED_FEATURES.md)**: Comprehensive guide to all enterprise features
- **[API Documentation](docs/api.md)**: RESTful API reference (coming soon)
- **[Configuration Guide](docs/config.md)**: Advanced configuration options (coming soon)
- **[Deployment Guide](docs/deployment.md)**: Production deployment instructions (coming soon)

## ğŸ§ª Testing

Run comprehensive tests for all advanced features:

```bash
# Test all advanced components
python test_advanced_features.py

# Test specific components
python -c "from src.drift_detector import DataDriftDetector; print('Drift detection working!')"
python -c "from src.online_learner import OnlineLearner; print('Online learning working!')"
python -c "from src.audit_system import MLAuditSystem; print('Audit system working!')"
python -c "from src.response_generator import AIResponseGenerator; print('AI Response Generator working!')"

# Test LLM integration
python -c "
from src.response_generator import AIResponseGenerator
gen = AIResponseGenerator()
response = gen.generate_response('Test ticket', 'Technical Issue', 0.9)
print('Response generated:', response.response_text[:50])
"
```

## ğŸ­ Production Deployment

### Enterprise Features for Production
- **Scalability**: Modular architecture supporting horizontal scaling
- **Security**: Audit trails, access controls, and data encryption
- **Compliance**: GDPR, data retention, and regulatory reporting
- **Monitoring**: Real-time performance, drift detection, and alerting
- **Reliability**: Model versioning, rollbacks, and A/B testing

### Deployment Checklist
- [ ] Configure audit logging and retention policies
- [ ] Set up drift detection thresholds and alerts
- [ ] Enable GDPR compliance features if required
- [ ] Configure online learning feedback loops
- [ ] Set up model versioning and A/B testing
- [ ] Implement monitoring dashboards and alerts

## ğŸš¨ Key Benefits

âœ… **Enterprise-Ready**: Production-grade MLOps with monitoring and compliance  
âœ… **Self-Improving**: Continuous learning and adaptation  
âœ… **AI-Powered Responses**: Intelligent response generation using open-source LLMs  
âœ… **Comprehensive Analytics**: Complete ticket data exploration and visualization  
âœ… **Explainable**: Full interpretability and bias monitoring  
âœ… **Compliant**: GDPR, audit trails, and regulatory features  
âœ… **Scalable**: Modular architecture for various deployment scenarios  
âœ… **User-Friendly**: Comprehensive web interface for all stakeholders

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Follow the existing code structure and patterns
4. Add tests for new features
5. Update documentation as needed
6. Submit a pull request

## ğŸ†˜ Support

- **Issues**: Open a GitHub issue for bugs or feature requests
- **Documentation**: See [ADVANCED_FEATURES.md](ADVANCED_FEATURES.md) for detailed guides
- **Enterprise Support**: Contact the development team for enterprise deployment assistance

---

**This Advanced AI Customer Support Ticket Classifier represents a state-of-the-art, enterprise-grade solution with comprehensive MLOps, compliance, and continuous improvement capabilities.**